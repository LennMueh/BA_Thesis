
@article{eniser_deepfault_2019,
	title = {{DeepFault}: Fault Localization for Deep Neural Networks},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1902.05974},
	doi = {10.48550/ARXIV.1902.05974},
	shorttitle = {{DeepFault}},
	abstract = {Deep Neural Networks ({DNNs}) are increasingly deployed in safety-critical applications including autonomous vehicles and medical diagnostics. To reduce the residual risk for unexpected {DNN} behaviour and provide evidence for their trustworthy operation, {DNNs} should be thoroughly tested. The {DeepFault} whitebox {DNN} testing approach presented in our paper addresses this challenge by employing suspiciousness measures inspired by fault localization to establish the hit spectrum of neurons and identify suspicious neurons whose weights have not been calibrated correctly and thus are considered responsible for inadequate {DNN} performance. {DeepFault} also uses a suspiciousness-guided algorithm to synthesize new inputs, from correctly classified inputs, that increase the activation values of suspicious neurons. Our empirical evaluation on several {DNN} instances trained on {MNIST} and {CIFAR}-10 datasets shows that {DeepFault} is effective in identifying suspicious neurons. Also, the inputs synthesized by {DeepFault} closely resemble the original inputs, exercise the identified suspicious neurons and are highly adversarial.},
	author = {Eniser, Hasan Ferit and Gerasimou, Simos and Sen, Alper},
	urldate = {2023-10-07},
	date = {2019},
	note = {Publisher: {arXiv}
Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG}), Software Engineering (cs.{SE})},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\VK9U5JCX\\Eniser et al. - 2019 - DeepFault Fault Localization for Deep Neural Netw.pdf:application/pdf},
}

@software{eniser_deepfault_2023,
	title = {{DeepFault}: Fault Localization for Deep Neural Networks},
	rights = {{GPL}-3.0},
	url = {https://github.com/hfeniser/DeepFault},
	shorttitle = {{DeepFault}},
	author = {Eniser, Hasan Ferit},
	urldate = {2023-10-08},
	date = {2023-07-31},
	note = {original-date: 2018-07-04T12:51:18Z},
}

@inproceedings{jones_empirical_2005,
	location = {Long Beach {CA} {USA}},
	title = {Empirical evaluation of the tarantula automatic fault-localization technique},
	isbn = {978-1-58113-993-8},
	url = {https://dl.acm.org/doi/10.1145/1101908.1101949},
	doi = {10.1145/1101908.1101949},
	eventtitle = {{ASE}05: International Conference on Automated Software Engineering 2005},
	pages = {273--282},
	booktitle = {Proceedings of the 20th {IEEE}/{ACM} International Conference on Automated Software Engineering},
	publisher = {{ACM}},
	author = {Jones, James A. and Harrold, Mary Jean},
	urldate = {2023-10-09},
	date = {2005-11-07},
	langid = {english},
	file = {Jones und Harrold - 2005 - Empirical evaluation of the tarantula automatic fa.pdf:C\:\\Users\\lenna\\Zotero\\storage\\2UV4XGWF\\Jones und Harrold - 2005 - Empirical evaluation of the tarantula automatic fa.pdf:application/pdf},
}

@article{ochiai_zoogeographical_1957,
	title = {Zoogeographical Studies on the Soleoid Fishes found in Japan and its Neighbouring Regions-I},
	volume = {22},
	issn = {1349-998X, 0021-5392},
	url = {http://www.jstage.jst.go.jp/article/suisan1932/22/9/22_9_522/_article/-char/ja/},
	doi = {10.2331/suisan.22.522},
	pages = {522--525},
	number = {9},
	journaltitle = {{NIPPON} {SUISAN} {GAKKAISHI}},
	shortjournal = {{NIPPON} {SUISAN} {GAKKAISHI}},
	author = {Ochiai, Akira},
	urldate = {2023-10-09},
	date = {1957},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\XSWB7UBJ\\Ochiai - 1957 - Zoogeographical Studies on the Soleoid Fishes foun.pdf:application/pdf},
}

@article{wong_dstar_2014,
	title = {The {DStar} Method for Effective Software Fault Localization},
	volume = {63},
	issn = {0018-9529, 1558-1721},
	url = {http://ieeexplore.ieee.org/document/6651713/},
	doi = {10.1109/TR.2013.2285319},
	pages = {290--308},
	number = {1},
	journaltitle = {{IEEE} Transactions on Reliability},
	shortjournal = {{IEEE} Trans. Rel.},
	author = {Wong, W. Eric and Debroy, Vidroha and Gao, Ruizhi and Li, Yihao},
	urldate = {2023-10-09},
	date = {2014-03},
	file = {Wong et al. - 2014 - The DStar Method for Effective Software Fault Loca.pdf:C\:\\Users\\lenna\\Zotero\\storage\\S6CPXJEW\\Wong et al. - 2014 - The DStar Method for Effective Software Fault Loca.pdf:application/pdf},
}

@article{wong_survey_2016,
	title = {A Survey on Software Fault Localization},
	volume = {42},
	issn = {0098-5589, 1939-3520},
	url = {http://ieeexplore.ieee.org/document/7390282/},
	doi = {10.1109/TSE.2016.2521368},
	pages = {707--740},
	number = {8},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IIEEE} Trans. Software Eng.},
	author = {Wong, W. Eric and Gao, Ruizhi and Li, Yihao and Abreu, Rui and Wotawa, Franz},
	urldate = {2023-10-09},
	date = {2016-08-01},
	file = {Wong et al. - 2016 - A Survey on Software Fault Localization.pdf:C\:\\Users\\lenna\\Zotero\\storage\\4NBAIAMK\\Wong et al. - 2016 - A Survey on Software Fault Localization.pdf:application/pdf},
}

@article{xiao_fashion-mnist_2017,
	title = {Fashion-{MNIST}: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1708.07747},
	doi = {10.48550/ARXIV.1708.07747},
	shorttitle = {Fashion-{MNIST}},
	abstract = {We present Fashion-{MNIST}, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-{MNIST} is intended to serve as a direct drop-in replacement for the original {MNIST} dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
	author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	urldate = {2023-10-10},
	date = {2017},
	note = {Publisher: {arXiv}
Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG}), Machine Learning (stat.{ML})},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\DS4TQHSW\\Xiao et al. - 2017 - Fashion-MNIST a Novel Image Dataset for Benchmark.pdf:application/pdf},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2023-12-27},
	date = {2015-05-28},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\5ZZBBVYE\\LeCun et al. - 2015 - Deep learning.pdf:application/pdf},
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation Applied to Handwritten Zip Code Recognition},
	volume = {1},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/1/4/541-551/5515},
	doi = {10.1162/neco.1989.1.4.541},
	abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
	pages = {541--551},
	number = {4},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {{LeCun}, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	urldate = {2023-12-27},
	date = {1989-12},
	langid = {english},
	file = {LeCun et al. - 1989 - Backpropagation Applied to Handwritten Zip Code Re.pdf:C\:\\Users\\lenna\\Zotero\\storage\\HXQ43KLA\\LeCun et al. - 1989 - Backpropagation Applied to Handwritten Zip Code Re.pdf:application/pdf},
}

@article{fukushima_visual_1969,
	title = {Visual Feature Extraction by a Multilayered Network of Analog Threshold Elements},
	volume = {5},
	issn = {0536-1567},
	url = {http://ieeexplore.ieee.org/document/4082265/},
	doi = {10.1109/TSSC.1969.300225},
	pages = {322--333},
	number = {4},
	journaltitle = {{IEEE} Transactions on Systems Science and Cybernetics},
	shortjournal = {{IEEE} Trans. Syst. Sci. Cyber.},
	author = {Fukushima, Kunihiko},
	urldate = {2023-12-27},
	date = {1969},
	file = {Fukushima - 1969 - Visual Feature Extraction by a Multilayered Networ.pdf:C\:\\Users\\lenna\\Zotero\\storage\\DCZKS8S3\\Fukushima - 1969 - Visual Feature Extraction by a Multilayered Networ.pdf:application/pdf},
}

@inproceedings{yamaguchi_neural_1990,
	title = {A neural network for speaker-independent isolated word recognition},
	url = {https://www.isca-speech.org/archive/icslp_1990/yamaguchi90c_icslp.html},
	doi = {10.21437/ICSLP.1990-282},
	eventtitle = {First International Conference on Spoken Language Processing ({ICSLP} 1990)},
	pages = {1077--1080},
	booktitle = {First International Conference on Spoken Language Processing ({ICSLP} 1990)},
	publisher = {{ISCA}},
	author = {Yamaguchi, Kouichi and Sakamoto, Kenji and Akabane, Toshio and Fujimoto, Yoshiji},
	urldate = {2023-12-27},
	date = {1990-11-18},
	langid = {english},
	file = {Yamaguchi et al. - 1990 - A neural network for speaker-independent isolated .pdf:C\:\\Users\\lenna\\Zotero\\storage\\TRCWW2NB\\Yamaguchi et al. - 1990 - A neural network for speaker-independent isolated .pdf:application/pdf},
}

@misc{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	number = {{arXiv}:1412.6980},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2023-12-27},
	date = {2017-01-29},
	eprinttype = {arxiv},
	eprint = {1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\lenna\\Zotero\\storage\\NPLQC9G8\\Kingma und Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\BRY34MXJ\\1412.html:text/html},
}

@article{jia_analysis_2011,
	title = {An Analysis and Survey of the Development of Mutation Testing},
	volume = {37},
	issn = {0098-5589},
	url = {http://ieeexplore.ieee.org/document/5487526/},
	doi = {10.1109/TSE.2010.62},
	pages = {649--678},
	number = {5},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IIEEE} Trans. Software Eng.},
	author = {Jia, Yue and Harman, Mark},
	urldate = {2023-12-27},
	date = {2011-09},
	file = {Jia und Harman - 2011 - An Analysis and Survey of the Development of Mutat.pdf:C\:\\Users\\lenna\\Zotero\\storage\\Y48WEV8H\\Jia und Harman - 2011 - An Analysis and Survey of the Development of Mutat.pdf:application/pdf},
}

@article{hamlet_testing_1977,
	title = {Testing Programs with the Aid of a Compiler},
	volume = {{SE}-3},
	issn = {0098-5589},
	url = {http://ieeexplore.ieee.org/document/1702444/},
	doi = {10.1109/TSE.1977.231145},
	pages = {279--290},
	number = {4},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IIEEE} Trans. Software Eng.},
	author = {Hamlet, R.G.},
	urldate = {2023-12-27},
	date = {1977-07},
	file = {Hamlet - 1977 - Testing Programs with the Aid of a Compiler.pdf:C\:\\Users\\lenna\\Zotero\\storage\\JCWB6XGX\\Hamlet - 1977 - Testing Programs with the Aid of a Compiler.pdf:application/pdf},
}

@article{demillo_hints_1978,
	title = {Hints on Test Data Selection: Help for the Practicing Programmer},
	volume = {11},
	issn = {0018-9162},
	url = {http://ieeexplore.ieee.org/document/1646911/},
	doi = {10.1109/C-M.1978.218136},
	shorttitle = {Hints on Test Data Selection},
	pages = {34--41},
	number = {4},
	journaltitle = {Computer},
	shortjournal = {Computer},
	author = {{DeMillo}, R.A. and Lipton, R.J. and Sayward, F.G.},
	urldate = {2023-12-27},
	date = {1978-04},
	file = {DeMillo et al. - 1978 - Hints on Test Data Selection Help for the Practic.pdf:C\:\\Users\\lenna\\Zotero\\storage\\IZCYZ58A\\DeMillo et al. - 1978 - Hints on Test Data Selection Help for the Practic.pdf:application/pdf},
}

@book{ammann_introduction_2017,
	location = {Cambridge, United Kingdom ; New York, {NY}, {USA}},
	edition = {Edition 2},
	title = {Introduction to software testing},
	isbn = {978-1-107-17201-2},
	pagetotal = {345},
	publisher = {Cambridge University Press},
	author = {Ammann, Paul and Offutt, Jeff},
	date = {2017},
	keywords = {Computer software, Testing},
	file = {Ammann und Offutt - 2017 - Introduction to software testing.pdf:C\:\\Users\\lenna\\Zotero\\storage\\QRVECTFY\\Ammann und Offutt - 2017 - Introduction to software testing.pdf:application/pdf},
}

@article{huang_survey_2020,
	title = {A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability},
	volume = {37},
	issn = {15740137},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013719302527},
	doi = {10.1016/j.cosrev.2020.100270},
	shorttitle = {A survey of safety and trustworthiness of deep neural networks},
	pages = {100270},
	journaltitle = {Computer Science Review},
	shortjournal = {Computer Science Review},
	author = {Huang, Xiaowei and Kroening, Daniel and Ruan, Wenjie and Sharp, James and Sun, Youcheng and Thamo, Emese and Wu, Min and Yi, Xinping},
	urldate = {2023-12-27},
	date = {2020-08},
	langid = {english},
	file = {Akzeptierte Version:C\:\\Users\\lenna\\Zotero\\storage\\H9XNXWKC\\Huang et al. - 2020 - A survey of safety and trustworthiness of deep neu.pdf:application/pdf},
}

@inproceedings{guo_dlfuzz_2018,
	location = {Lake Buena Vista {FL} {USA}},
	title = {{DLFuzz}: differential fuzzing testing of deep learning systems},
	isbn = {978-1-4503-5573-5},
	url = {https://dl.acm.org/doi/10.1145/3236024.3264835},
	doi = {10.1145/3236024.3264835},
	shorttitle = {{DLFuzz}},
	eventtitle = {{ESEC}/{FSE} '18: 26th {ACM} Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	pages = {739--743},
	booktitle = {Proceedings of the 2018 26th {ACM} Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Guo, Jianmin and Jiang, Yu and Zhao, Yue and Chen, Quan and Sun, Jiaguang},
	urldate = {2023-12-27},
	date = {2018-10-26},
	langid = {english},
	keywords = {Fuzzing},
	file = {Eingereichte Version:C\:\\Users\\lenna\\Zotero\\storage\\YN33DLL6\\Guo et al. - 2018 - DLFuzz differential fuzzing testing of deep learn.pdf:application/pdf},
}

@article{sun_deepmc_2023,
	title = {{DeepMC}: {DNN} test sample optimization method jointly guided by misclassification and coverage},
	volume = {53},
	issn = {0924-669X, 1573-7497},
	url = {https://link.springer.com/10.1007/s10489-022-04323-4},
	doi = {10.1007/s10489-022-04323-4},
	shorttitle = {{DeepMC}},
	pages = {15787--15801},
	number = {12},
	journaltitle = {Applied Intelligence},
	shortjournal = {Appl Intell},
	author = {Sun, Jiaze and Li, Juan and Wen, Sulei},
	urldate = {2023-12-27},
	date = {2023-06},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\LBBWCKGU\\Sun et al. - 2023 - DeepMC DNN test sample optimization method jointl.pdf:application/pdf},
}

@inproceedings{keller_critical_2017,
	location = {Prague, Czech Republic},
	title = {A Critical Evaluation of Spectrum-Based Fault Localization Techniques on a Large-Scale Software System},
	isbn = {978-1-5386-0592-9},
	url = {http://ieeexplore.ieee.org/document/8009915/},
	doi = {10.1109/QRS.2017.22},
	eventtitle = {2017 {IEEE} International Conference on Software Quality, Reliability and Security ({QRS})},
	pages = {114--125},
	booktitle = {2017 {IEEE} International Conference on Software Quality, Reliability and Security ({QRS})},
	publisher = {{IEEE}},
	author = {Keller, Fabian and Grunske, Lars and Heiden, Simon and Filieri, Antonio and Van Hoorn, Andre and Lo, David},
	urldate = {2023-12-27},
	date = {2017-07},
	file = {Eingereichte Version:C\:\\Users\\lenna\\Zotero\\storage\\87I4N8EC\\Keller et al. - 2017 - A Critical Evaluation of Spectrum-Based Fault Loca.pdf:application/pdf},
}

@article{abreu_practical_2009,
	title = {A practical evaluation of spectrum-based fault localization},
	volume = {82},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121209001319},
	doi = {10.1016/j.jss.2009.06.035},
	pages = {1780--1792},
	number = {11},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Abreu, Rui and Zoeteweij, Peter and Golsteijn, Rob and Van Gemund, Arjan J.C.},
	urldate = {2023-12-27},
	date = {2009-11},
	langid = {english},
	file = {Abreu et al. - 2009 - A practical evaluation of spectrum-based fault loc.pdf:C\:\\Users\\lenna\\Zotero\\storage\\FAQLBLV9\\Abreu et al. - 2009 - A practical evaluation of spectrum-based fault loc.pdf:application/pdf},
}

@article{sarhan_survey_2022,
	title = {A Survey of Challenges in Spectrum-Based Software Fault Localization},
	volume = {10},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9684433/},
	doi = {10.1109/ACCESS.2022.3144079},
	pages = {10618--10639},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Sarhan, Qusay Idrees and Beszedes, Arpad},
	urldate = {2023-12-27},
	date = {2022},
	file = {Sarhan und Beszedes - 2022 - A Survey of Challenges in Spectrum-Based Software .pdf:C\:\\Users\\lenna\\Zotero\\storage\\9BHL9NBR\\Sarhan und Beszedes - 2022 - A Survey of Challenges in Spectrum-Based Software .pdf:application/pdf},
}

@article{naish_model_2011,
	title = {A model for spectra-based software diagnosis},
	volume = {20},
	issn = {1049-331X, 1557-7392},
	url = {https://dl.acm.org/doi/10.1145/2000791.2000795},
	doi = {10.1145/2000791.2000795},
	abstract = {This article presents an improved approach to assist diagnosis of failures in software (fault localisation) by ranking program statements or blocks in accordance with to how likely they are to be buggy. We present a very simple single-bug program to model the problem. By examining different possible execution paths through this model program over a number of test cases, the effectiveness of different proposed spectral ranking methods can be evaluated in idealised conditions. The results are remarkably consistent to those arrived at empirically using the Siemens test suite and Space benchmarks. The model also helps identify groups of metrics that are equivalent for ranking. Due to the simplicity of the model, an optimal ranking method can be devised. This new method out-performs previously proposed methods for the model program, the Siemens test suite and Space. It also helps provide insight into other ranking methods.},
	pages = {1--32},
	number = {3},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Naish, Lee and Lee, Hua Jie and Ramamohanarao, Kotagiri},
	urldate = {2023-12-27},
	date = {2011-08},
	langid = {english},
	file = {Naish et al. - 2011 - A model for spectra-based software diagnosis.pdf:C\:\\Users\\lenna\\Zotero\\storage\\3WM8LNSW\\Naish et al. - 2011 - A model for spectra-based software diagnosis.pdf:application/pdf},
}

@inproceedings{zhou_computation_1988,
	location = {San Diego, {CA}, {USA}},
	title = {Computation of optical flow using a neural network},
	isbn = {978-0-7803-0999-9},
	url = {http://ieeexplore.ieee.org/document/23914/},
	doi = {10.1109/ICNN.1988.23914},
	eventtitle = {Proceedings of 1993 {IEEE} International Conference on Neural Networks ({ICNN} '93)},
	pages = {71--78 vol.2},
	booktitle = {{IEEE} International Conference on Neural Networks},
	publisher = {{IEEE}},
	author = {{Zhou} and {Chellappa}},
	urldate = {2023-12-30},
	date = {1988},
	file = {Zhou und Chellappa - 1988 - Computation of optical flow using a neural network.pdf:C\:\\Users\\lenna\\Zotero\\storage\\M9KSV3RV\\Zhou und Chellappa - 1988 - Computation of optical flow using a neural network.pdf:application/pdf},
}

@online{riebesell_convolution_2022,
	title = {Convolution Operator},
	url = {https://tikz.net/conv2d/},
	abstract = {Simple 2d example illustrating the role of the Jacobian determinant in the change of variables formula. Inspired by Ari Seff in https://youtu.be/i7LjDvsLWCg?t=250.},
	author = {Riebesell, Janosh},
	urldate = {2023-12-30},
	date = {2022-04-09},
	langid = {american},
	file = {Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\GM3QH9H3\\conv2d.html:text/html},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. and Bottou, L. and Weinberger, K. Q.},
	date = {2012},
	keywords = {⛔ No {DOI} found},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\87VBCESB\\Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf},
}

@article{szegedy_going_2014,
	title = {Going Deeper with Convolutions},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1409.4842},
	doi = {10.48550/ARXIV.1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the {ImageNet} Large-Scale Visual Recognition Challenge 2014 ({ILSVRC} 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for {ILSVRC} 2014 is called {GoogLeNet}, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	urldate = {2023-12-30},
	date = {2014},
	note = {Publisher: {arXiv}
Version Number: 1},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\INBMFT48\\Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:application/pdf},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	pages = {533--536},
	number = {6088},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	urldate = {2023-12-30},
	date = {1986-10},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\MBVVDD4P\\Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf:application/pdf},
}

@online{neutelings_neural_2021,
	title = {Neural networks},
	url = {https://tikz.net/neural_networks/},
	abstract = {Some examples of neural network architectures: deep neural networks ({DNN}), deep convolutional neural network ({CNN}), autoencoders (encoder+decoder), and activation function in neurons. Basic idea The full {LaTeX} code at the bottom of this post uses the listofitems library, so one can pre-define an array of the number of nodes in each layer, which is easier…},
	author = {Neutelings, Izaak},
	urldate = {2023-12-29},
	date = {2021-09-12},
	langid = {american},
	file = {Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\LB8JR76I\\neural_networks.html:text/html},
}

@misc{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5\% (7.7\% point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	number = {{arXiv}:1810.04805},
	publisher = {{arXiv}},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2023-12-29},
	date = {2019-05-24},
	eprinttype = {arxiv},
	eprint = {1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\lenna\\Zotero\\storage\\WIH73JEL\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\CDKQIVSP\\1810.html:text/html},
}

@article{hendrycks_gaussian_2016,
	title = {Gaussian Error Linear Units ({GELUs})},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1606.08415},
	doi = {10.48550/ARXIV.1606.08415},
	abstract = {We propose the Gaussian Error Linear Unit ({GELU}), a high-performing neural network activation function. The {GELU} activation function is \${xΦ}(x)\$, where \$Φ(x)\$ the standard Gaussian cumulative distribution function. The {GELU} nonlinearity weights inputs by their value, rather than gates inputs by their sign as in {ReLUs} (\$x{\textbackslash}mathbf\{1\}\_\{x\&gt;0\}\$). We perform an empirical evaluation of the {GELU} nonlinearity against the {ReLU} and {ELU} activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	urldate = {2023-12-29},
	date = {2016},
	note = {Publisher: {arXiv}
Version Number: 5},
	keywords = {{FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\4LZJ5IAJ\\Hendrycks und Gimpel - 2016 - Gaussian Error Linear Units (GELUs).pdf:application/pdf},
}

@inproceedings{glorot_deep_2011,
	location = {Fort Lauderdale, {FL}, {USA}},
	title = {Deep Sparse Rectifier Neural Networks},
	volume = {15},
	url = {https://proceedings.mlr.press/v15/glorot11a.html},
	series = {Proceedings of Machine Learning Research},
	abstract = {While logistic sigmoid neurons are more biologically plausible than hyperbolic tangent neurons, the latter work better for training multi-layer neural networks. This paper shows that rectifying neurons are an even better model of biological neurons and yield equal or better performance than hyperbolic tangent networks in spite of the hard non-linearity and non-differentiability at zero, creating sparse representations with true zeros which seem remarkably suitable for naturally sparse data. Even though they can take advantage of semi-supervised setups with extra-unlabeled data, deep rectifier networks can reach their best performance without requiring any unsupervised pre-training on purely supervised tasks with large labeled datasets. Hence, these results can be seen as a new milestone in the attempts at understanding the difficulty in training deep but purely supervised neural networks, and closing the performance gap between neural networks learnt with and without unsupervised pre-training.},
	pages = {315--323},
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	editor = {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
	date = {2011-04-11},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\D5Y6EL6U\\Glorot et al. - 2011 - Deep Sparse Rectifier Neural Networks.pdf:application/pdf},
}

@article{fukushima_cognitron_1975,
	title = {Cognitron: A self-organizing multilayered neural network},
	volume = {20},
	issn = {0340-1200, 1432-0770},
	url = {http://link.springer.com/10.1007/BF00342633},
	doi = {10.1007/BF00342633},
	shorttitle = {Cognitron},
	pages = {121--136},
	number = {3},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol. Cybernetics},
	author = {Fukushima, Kunihiko},
	urldate = {2023-12-29},
	date = {1975},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\5DZ5EF4V\\Fukushima - 1975 - Cognitron A self-organizing multilayered neural n.pdf:application/pdf},
}

@inproceedings{glorot_understanding_2010,
	location = {Chia Laguna Resort, Sardinia, Italy},
	title = {Understanding the difficulty of training deep feedforward neural networks},
	volume = {9},
	url = {https://proceedings.mlr.press/v9/glorot10a.html},
	series = {Proceedings of Machine Learning Research},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	pages = {249--256},
	booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{PMLR}},
	author = {Glorot, Xavier and Bengio, Yoshua},
	editor = {Teh, Yee Whye and Titterington, Mike},
	date = {2010-05-13},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\VNRD9EEY\\Glorot und Bengio - 2010 - Understanding the difficulty of training deep feed.pdf:application/pdf},
}

@online{noauthor_tfkeraslayersdense_2023,
	title = {tf.keras.layers.Dense  {\textbar}  {TensorFlow} v2.14.0},
	url = {https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense},
	urldate = {2023-12-29},
	date = {2023-09-27},
	file = {tf.keras.layers.Dense  |  TensorFlow v2.14.0:C\:\\Users\\lenna\\Zotero\\storage\\CAWMREMW\\Dense.html:text/html},
}

@book{trask_grokking_2019,
	location = {Shelter Island},
	title = {Grokking deep learning},
	isbn = {978-1-61729-370-2},
	abstract = {"Grokking Deep Learning teaches you to build deep learning neural networks from scratch! In his engaging style, seasoned deep learning expert Andrew Trask shows you the science under the hood, so you grok for yourself every detail of training neural networks. Using only Python and its math-supporting library, {NumPy}, you'll train your own neural networks to see and understand images, translate text into different languages, and even write like Shakespeare!"--},
	pagetotal = {309},
	publisher = {Manning},
	author = {Trask, Andrew W.},
	date = {2019},
	note = {{OCLC}: on1084981313},
	keywords = {Machine learning, Neural networks (Computer science), Python (Computer program language)},
	file = {Trask - 2019 - Grokking deep learning.pdf:C\:\\Users\\lenna\\Zotero\\storage\\BPLD3I2J\\Trask - 2019 - Grokking deep learning.pdf:application/pdf},
}

@book{goodfellow_deep_2016,
	location = {Cambridge, Massachusetts},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	series = {Adaptive computation and machine learning},
	pagetotal = {775},
	publisher = {The {MIT} Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	date = {2016},
	keywords = {Machine learning},
	file = {Goodfellow et al. - 2016 - Deep learning.pdf:C\:\\Users\\lenna\\Zotero\\storage\\MIZTQGIU\\Goodfellow et al. - 2016 - Deep learning.pdf:application/pdf},
}

@inproceedings{boureau_theoretical_2010,
	title = {A theoretical analysis of feature pooling in visual recognition},
	pages = {111--118},
	booktitle = {Proceedings of the 27th international conference on machine learning ({ICML}-10)},
	author = {Boureau, Y-Lan and Ponce, Jean and {LeCun}, Yann},
	date = {2010},
	keywords = {⛔ No {DOI} found},
	file = {Boureau et al. - 2010 - A theoretical analysis of feature pooling in visua.pdf:C\:\\Users\\lenna\\Zotero\\storage\\87LRD8XW\\Boureau et al. - 2010 - A theoretical analysis of feature pooling in visua.pdf:application/pdf},
}

@inproceedings{jain_supervised_2007,
	location = {Rio de Janeiro, Brazil},
	title = {Supervised Learning of Image Restoration with Convolutional Networks},
	isbn = {978-1-4244-1630-1},
	url = {http://ieeexplore.ieee.org/document/4408909/},
	doi = {10.1109/ICCV.2007.4408909},
	eventtitle = {2007 {IEEE} 11th International Conference on Computer Vision},
	pages = {1--8},
	booktitle = {2007 {IEEE} 11th International Conference on Computer Vision},
	publisher = {{IEEE}},
	author = {Jain, Viren and Murray, Joseph F. and Roth, Fabian and Turaga, Srinivas and Zhigulin, Valentin and Briggman, Kevin L. and Helmstaedter, Moritz N. and Denk, Winfried and Seung, H. Sebastian},
	urldate = {2024-01-03},
	date = {2007},
	file = {Jain et al. - 2007 - Supervised Learning of Image Restoration with Conv.pdf:C\:\\Users\\lenna\\Zotero\\storage\\PHT4F9BL\\Jain et al. - 2007 - Supervised Learning of Image Restoration with Conv.pdf:application/pdf},
}

@inproceedings{boureau_ask_2011,
	location = {Barcelona, Spain},
	title = {Ask the locals: Multi-way local pooling for image recognition},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	url = {http://ieeexplore.ieee.org/document/6126555/},
	doi = {10.1109/ICCV.2011.6126555},
	shorttitle = {Ask the locals},
	eventtitle = {2011 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {2651--2658},
	booktitle = {2011 International Conference on Computer Vision},
	publisher = {{IEEE}},
	author = {Boureau, Y-Lan and Le Roux, Nicolas and Bach, Francis and Ponce, Jean and {LeCun}, Yann},
	urldate = {2024-01-03},
	date = {2011-11},
	file = {Eingereichte Version:C\:\\Users\\lenna\\Zotero\\storage\\QE3P8UIB\\Boureau et al. - 2011 - Ask the locals Multi-way local pooling for image .pdf:application/pdf},
}

@inproceedings{zhou_computation_1988-1,
	location = {San Diego, {CA}, {USA}},
	title = {Computation of optical flow using a neural network},
	isbn = {978-0-7803-0999-9},
	url = {http://ieeexplore.ieee.org/document/23914/},
	doi = {10.1109/ICNN.1988.23914},
	eventtitle = {Proceedings of 1993 {IEEE} International Conference on Neural Networks ({ICNN} '93)},
	pages = {71--78 vol.2},
	booktitle = {{IEEE} International Conference on Neural Networks},
	publisher = {{IEEE}},
	author = {{Zhou} and {Chellappa}},
	urldate = {2024-01-03},
	date = {1988},
	file = {Zhou und Chellappa - 1988 - Computation of optical flow using a neural network.pdf:C\:\\Users\\lenna\\Zotero\\storage\\YL4LKQ62\\Zhou und Chellappa - 1988 - Computation of optical flow using a neural network.pdf:application/pdf},
}

@inproceedings{zhou_stereo_1988,
	location = {New York, {NY}, {USA}},
	title = {Stereo matching using a neural network},
	url = {http://ieeexplore.ieee.org/document/196745/},
	doi = {10.1109/ICASSP.1988.196745},
	eventtitle = {{ICASSP}-88., International Conference on Acoustics, Speech, and Signal Processing},
	pages = {940--943},
	booktitle = {{ICASSP}-88., International Conference on Acoustics, Speech, and Signal Processing},
	publisher = {{IEEE}},
	author = {Zhou, Y.T. and Chellappa, R.},
	urldate = {2024-01-03},
	date = {1988},
}

@article{kingma_adam_2014,
	title = {Adam: A Method for Stochastic Optimization},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1412.6980},
	doi = {10.48550/ARXIV.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2024-01-03},
	date = {2014},
	note = {Publisher: {arXiv}
Version Number: 9},
	keywords = {{FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\AJRQB6IZ\\Kingma und Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf},
}

@article{huang_survey_2020-1,
	title = {A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability},
	volume = {37},
	issn = {15740137},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013719302527},
	doi = {10.1016/j.cosrev.2020.100270},
	shorttitle = {A survey of safety and trustworthiness of deep neural networks},
	pages = {100270},
	journaltitle = {Computer Science Review},
	shortjournal = {Computer Science Review},
	author = {Huang, Xiaowei and Kroening, Daniel and Ruan, Wenjie and Sharp, James and Sun, Youcheng and Thamo, Emese and Wu, Min and Yi, Xinping},
	urldate = {2024-01-04},
	date = {2020-08},
	langid = {english},
	file = {1-s2.0-S1574013719302527-main.pdf:C\:\\Users\\lenna\\Zotero\\storage\\AIY9VV5Q\\1-s2.0-S1574013719302527-main.pdf:application/pdf;Akzeptierte Version:C\:\\Users\\lenna\\Zotero\\storage\\WLNYWWSM\\Huang et al. - 2020 - A survey of safety and trustworthiness of deep neu.pdf:application/pdf},
}

@incollection{beyer_feature-guided_2018,
	location = {Cham},
	title = {Feature-Guided Black-Box Safety Testing of Deep Neural Networks},
	volume = {10805},
	isbn = {978-3-319-89959-6 978-3-319-89960-2},
	url = {http://link.springer.com/10.1007/978-3-319-89960-2_22},
	pages = {408--426},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer International Publishing},
	author = {Wicker, Matthew and Huang, Xiaowei and Kwiatkowska, Marta},
	editor = {Beyer, Dirk and Huisman, Marieke},
	urldate = {2024-01-04},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-89960-2_22},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {Input Mutation, Safety Coverage},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\IG5JW6PX\\Wicker et al. - 2018 - Feature-Guided Black-Box Safety Testing of Deep Ne.pdf:application/pdf},
}

@misc{odena_tensorfuzz_2018,
	title = {{TensorFuzz}: Debugging Neural Networks with Coverage-Guided Fuzzing},
	url = {http://arxiv.org/abs/1807.10875},
	shorttitle = {{TensorFuzz}},
	abstract = {Machine learning models are notoriously difficult to interpret and debug. This is particularly true of neural networks. In this work, we introduce automated software testing techniques for neural networks that are well-suited to discovering errors which occur only for rare inputs. Specifically, we develop coverage-guided fuzzing ({CGF}) methods for neural networks. In {CGF}, random mutations of inputs to a neural network are guided by a coverage metric toward the goal of satisfying user-specified constraints. We describe how fast approximate nearest neighbor algorithms can provide this coverage metric. We then discuss the application of {CGF} to the following goals: finding numerical errors in trained neural networks, generating disagreements between neural networks and quantized versions of those networks, and surfacing undesirable behavior in character level language models. Finally, we release an open source library called {TensorFuzz} that implements the described techniques.},
	number = {{arXiv}:1807.10875},
	publisher = {{arXiv}},
	author = {Odena, Augustus and Goodfellow, Ian},
	urldate = {2024-01-04},
	date = {2018-07-27},
	eprinttype = {arxiv},
	eprint = {1807.10875 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Fuzzing},
	file = {arXiv Fulltext PDF:C\:\\Users\\lenna\\Zotero\\storage\\VZYA9ED4\\Odena und Goodfellow - 2018 - TensorFuzz Debugging Neural Networks with Coverag.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\6VTYPRUZ\\1807.html:text/html},
}

@misc{gopinath_symbolic_2018,
	title = {Symbolic Execution for Deep Neural Networks},
	url = {http://arxiv.org/abs/1807.10439},
	abstract = {Deep Neural Networks ({DNN}) are increasingly used in a variety of applications, many of them with substantial safety and security concerns. This paper introduces {DeepCheck}, a new approach for validating {DNNs} based on core ideas from program analysis, specifically from symbolic execution. The idea is to translate a {DNN} into an imperative program, thereby enabling program analysis to assist with {DNN} validation. A basic translation however creates programs that are very complex to analyze. {DeepCheck} introduces novel techniques for lightweight symbolic analysis of {DNNs} and applies them in the context of image classification to address two challenging problems in {DNN} analysis: 1) identification of important pixels (for attribution and adversarial generation); and 2) creation of 1-pixel and 2-pixel attacks. Experimental results using the {MNIST} data-set show that {DeepCheck}'s lightweight symbolic analysis provides a valuable tool for {DNN} validation.},
	number = {{arXiv}:1807.10439},
	publisher = {{arXiv}},
	author = {Gopinath, Divya and Wang, Kaiyuan and Zhang, Mengshi and Pasareanu, Corina S. and Khurshid, Sarfraz},
	urldate = {2024-01-04},
	date = {2018-07-27},
	eprinttype = {arxiv},
	eprint = {1807.10439 [cs]},
	keywords = {Computer Science - Software Engineering, Computer Science - Cryptography and Security, Symbolic Execution},
	file = {arXiv Fulltext PDF:C\:\\Users\\lenna\\Zotero\\storage\\XS6PZIRH\\Gopinath et al. - 2018 - Symbolic Execution for Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\I7XZLNY4\\1807.html:text/html},
}

@inproceedings{sun_deepconcolic_2019,
	location = {Montreal, {QC}, Canada},
	title = {{DeepConcolic}: Testing and Debugging Deep Neural Networks},
	isbn = {978-1-72811-764-5},
	url = {https://ieeexplore.ieee.org/document/8802786/},
	doi = {10.1109/ICSE-Companion.2019.00051},
	shorttitle = {{DeepConcolic}},
	eventtitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering: Companion Proceedings ({ICSE}-Companion)},
	pages = {111--114},
	booktitle = {2019 {IEEE}/{ACM} 41st International Conference on Software Engineering: Companion Proceedings ({ICSE}-Companion)},
	publisher = {{IEEE}},
	author = {Sun, Youcheng and Huang, Xiaowei and Kroening, Daniel and Sharp, James and Hill, Matthew and Ashmore, Rob},
	urldate = {2024-01-04},
	date = {2019-05},
	keywords = {Symbolic Execution, Neuron Coverage},
	file = {Sun et al. - 2019 - DeepConcolic Testing and Debugging Deep Neural Ne.pdf:C\:\\Users\\lenna\\Zotero\\storage\\K8KK573D\\Sun et al. - 2019 - DeepConcolic Testing and Debugging Deep Neural Ne.pdf:application/pdf},
}

@report{hayhurst_practical_2001,
	title = {A Practical Tutorial on Modified Condition/Decision Coverage},
	url = {https://ntrs.nasa.gov/citations/20010057789},
	abstract = {This tutorial provides a practical approach to assessing modified condition/decision coverage ({MC}/{DC}) for aviation software products that must comply with regulatory guidance for {DO}-178B level A software. The tutorial's approach to {MC}/{DC} is a 5-step process that allows a certification authority or verification analyst to evaluate {MC}/{DC} claims without the aid of a coverage tool. In addition to the {MC}/{DC} approach, the tutorial addresses factors to consider in selecting and qualifying a structural coverage analysis tool, tips for reviewing life cycle data related to {MC}/{DC}, and pitfalls common to structural coverage analysis.},
	number = {L-18088},
	author = {Hayhurst, Kelly J. and Veerhusen, Dan S. and Chilenski, John J. and Rierson, Leanna K.},
	urldate = {2024-01-04},
	date = {2001-05-01},
	note = {{NTRS} Author Affiliations: {NASA} Langley Research Center, Rockwell Collins, Inc., Boeing Co., Federal Aviation Administration
{NTRS} Document {ID}: 20010057789
{NTRS} Research Center: Langley Research Center ({LaRC})},
	keywords = {Computer Programming And Software},
	file = {Hayhurst et al. - 2001 - A Practical Tutorial on Modified ConditionDecisio.pdf:C\:\\Users\\lenna\\Zotero\\storage\\6CXKM9MN\\Hayhurst et al. - 2001 - A Practical Tutorial on Modified ConditionDecisio.pdf:application/pdf;Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\DZGLMH26\\20010057789.html:text/html},
}

@incollection{lahiri_quantitative_2018,
	location = {Cham},
	title = {Quantitative Projection Coverage for Testing {ML}-enabled Autonomous Systems},
	volume = {11138},
	isbn = {978-3-030-01089-8 978-3-030-01090-4},
	url = {http://link.springer.com/10.1007/978-3-030-01090-4_8},
	pages = {126--142},
	booktitle = {Automated Technology for Verification and Analysis},
	publisher = {Springer International Publishing},
	author = {Cheng, Chih-Hong and Huang, Chung-Hao and Yasuoka, Hirotoshi},
	editor = {Lahiri, Shuvendu K. and Wang, Chao},
	urldate = {2024-01-04},
	date = {2018},
	doi = {10.1007/978-3-030-01090-4_8},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {Quantitative projection coverage},
	file = {Eingereichte Version:C\:\\Users\\lenna\\Zotero\\storage\\2HWT8P6Q\\Cheng et al. - 2018 - Quantitative Projection Coverage for Testing ML-en.pdf:application/pdf},
}

@collection{wong_handbook_2023,
	location = {Hoboken, New Jersey, Piscataway, {NJ}},
	title = {Handbook of software fault localization: foundations and advances},
	isbn = {978-1-119-88092-9},
	shorttitle = {Handbook of software fault localization},
	abstract = {"Software fault localization is one of the most expensive activities in program debugging. It can be further divided into two major parts. The first part is to use a technique to identify suspicious code that may contain program bugs. The second part is for programmers to actually examine the identified code to decide whether it indeed contains bugs. Fault localization has historically been a manual task that has been recognized to be time consuming and tedious as well as prohibitively expensive, given the size and complexity of large-scale software systems today. Furthermore, manual fault localization relies heavily on the software developer's experience, judgment, and intuition to identify and prioritize code that is likely to be faulty. These limitations have led to a surge of interest in developing techniques that can partially or fully automate the localization of faults in software while reducing human input"-- Provided by publisher},
	publisher = {John Wiley \& Sons, Inc ; {IEEE} Press},
	editor = {Wong, W. Eric and Tse, T. H.},
	date = {2023},
	note = {{OCLC}: 1345466980},
	file = {Wong und Tse - 2023 - Handbook of software fault localization foundatio.pdf:C\:\\Users\\lenna\\Zotero\\storage\\WUGFAFA2\\Wong und Tse - 2023 - Handbook of software fault localization foundatio.pdf:application/pdf},
}

@book{parsa_software_2023,
	location = {Cham},
	title = {Software testing automation: testability evaluation, refactoring, test data generation and fault localization},
	isbn = {978-3-031-22057-9},
	shorttitle = {Software testing automation},
	abstract = {This book is about the design and development of tools for software testing. It intends to get the reader involved in software testing rather than simply memorizing the concepts. The source codes are downloadable from the book website. The book has three parts: software testability, fault localization, and test data generation. Part I describes unit and acceptance tests and proposes a new method called testability-driven development ({TsDD}) in support of {TDD} and {BDD}. {TsDD} uses a machine learning model to measure testability before and after refactoring. The reader will learn how to develop the testability prediction model and write software tools for automatic refactoring. Part {II} focuses on developing tools for automatic fault localization. This part shows the reader how to use a compiler generator to instrument source code, create control flow graphs, identify prime paths, and slice the source code. On top of these tools, a software tool, Diagnoser, is offered to facilitate experimenting with and developing new fault localization algorithms. Diagnoser takes a source code and its test suite as input and reports the coverage provided by the test cases and the suspiciousness score for each statement. Part {III} proposes using software testing as a prominent part of the cyber-physical system software to uncover and model unknown physical behaviors and the underlying physical rules. The reader will get insights into developing software tools to generate white box test data.},
	publisher = {Springer},
	author = {Parsa, Saeed},
	date = {2023},
	note = {{OCLC}: 1374251026},
	file = {Parsa - 2023 - Software testing automation testability evaluatio.pdf:C\:\\Users\\lenna\\Zotero\\storage\\7H47FSF9\\Parsa - 2023 - Software testing automation testability evaluatio.pdf:application/pdf},
}

@book{xie_essential_2021,
	location = {Singapore},
	title = {Essential spectrum-based fault localization},
	isbn = {978-981-336-179-9},
	abstract = {Program debugging has always been a difficult and time-consuming task in the context of software development, where spectrum-based fault localization ({SBFL}) is one of the most widely studied families of techniques. While it's not particularly difficult to learn about the process and empirical performance of a particular {SBFL} technique from the available literature, researchers and practitioners aren't always familiar with the underlying theories. This book provides the first comprehensive guide to fundamental theories in {SBFL}, while also addressing some emerging challenges in this area. The theoretical framework introduced here reveals the intrinsic relations between various risk evaluation formulas, making it possible to construct a formula performance hierarchy. Further extensions of the framework provide a sufficient and necessary condition for a general maximal formula, as well as performance comparisons for hybrid {SBFL} methods. With regard to emerging challenges in {SBFL}, the book mainly covers the frequently encountered oracle problem in {SBFL} and introduces a metamorphic slice-based solution. In addition, it discusses the challenge of multiple-fault localization and presents cutting-edge approaches to overcoming it. {SBFL} is a widely studied research area with a massive amount of publications. Thus, it is essential that the software engineering community, especially those involved in program debugging, software maintenance and software quality assurance (including both newcomers and researchers who want to gain deeper insights) understand the most fundamental theories - which could also be very helpful to ensuring the healthy development of the field},
	publisher = {Springer},
	author = {Xie, Xiaoyuan and Xu, Baowen},
	date = {2021},
	note = {{OCLC}: 1236368200},
	file = {Xie und Xu - 2021 - Essential spectrum-based fault localization.pdf:C\:\\Users\\lenna\\Zotero\\storage\\P43NLHC3\\Xie und Xu - 2021 - Essential spectrum-based fault localization.pdf:application/pdf},
}

@inproceedings{hua_jie_lee_study_2009,
	location = {Beijing, China},
	title = {Study of the relationship of bug consistency with respect to performance of spectra metrics},
	isbn = {978-1-4244-4519-6},
	url = {http://ieeexplore.ieee.org/document/5234512/},
	doi = {10.1109/ICCSIT.2009.5234512},
	eventtitle = {2009 2nd {IEEE} International Conference on Computer Science and Information Technology},
	pages = {501--508},
	booktitle = {2009 2nd {IEEE} International Conference on Computer Science and Information Technology},
	publisher = {{IEEE}},
	author = {{Hua Jie Lee} and Naish, Lee and {Kotagiri Ramamohanarao}},
	urldate = {2024-01-05},
	date = {2009},
	keywords = {Trantula metric symplified.},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\2Q6V9238\\Hua Jie Lee et al. - 2009 - Study of the relationship of bug consistency with .pdf:application/pdf},
}

@article{wong_survey_2016-1,
	title = {A Survey on Software Fault Localization},
	volume = {42},
	issn = {0098-5589, 1939-3520},
	url = {http://ieeexplore.ieee.org/document/7390282/},
	doi = {10.1109/TSE.2016.2521368},
	pages = {707--740},
	number = {8},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IIEEE} Trans. Software Eng.},
	author = {Wong, W. Eric and Gao, Ruizhi and Li, Yihao and Abreu, Rui and Wotawa, Franz},
	urldate = {2024-01-05},
	date = {2016-08-01},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\LBVSZYZ7\\Wong et al. - 2016 - A Survey on Software Fault Localization.pdf:application/pdf},
}

@article{yoo_human_2017,
	title = {Human Competitiveness of Genetic Programming in Spectrum-Based Fault Localisation: Theoretical and Empirical Analysis},
	volume = {26},
	issn = {1049-331X, 1557-7392},
	url = {https://dl.acm.org/doi/10.1145/3078840},
	doi = {10.1145/3078840},
	shorttitle = {Human Competitiveness of Genetic Programming in Spectrum-Based Fault Localisation},
	abstract = {We report on the application of Genetic Programming to Software Fault Localisation, a problem in the area of Search-Based Software Engineering ({SBSE}). We give both empirical and theoretical evidence for the human competitiveness of the evolved fault localisation formulæ under the single fault scenario, compared to those generated by human ingenuity and reported in many papers, published over more than a decade. Though there have been previous human competitive results claimed for {SBSE} problems, this is the first time that evolved solutions have been formally proved to be human competitive. We further prove that no future human investigation could outperform the evolved solutions. We complement these proofs with an empirical analysis of both human and evolved solutions, which indicates that the evolved solutions are not only theoretically human competitive, but also convey similar practical benefits to human-evolved counterparts.},
	pages = {1--30},
	number = {1},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	shortjournal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Yoo, Shin and Xie, Xiaoyuan and Kuo, Fei-Ching and Chen, Tsong Yueh and Harman, Mark},
	urldate = {2024-01-05},
	date = {2017-01-31},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\SCKXPB3H\\Yoo et al. - 2017 - Human Competitiveness of Genetic Programming in Sp.pdf:application/pdf},
}

@inproceedings{petrovic_industrial_2018,
	location = {Vasteras},
	title = {An Industrial Application of Mutation Testing: Lessons, Challenges, and Research Directions},
	isbn = {978-1-5386-6352-3},
	url = {https://ieeexplore.ieee.org/document/8411730/},
	doi = {10.1109/ICSTW.2018.00027},
	shorttitle = {An Industrial Application of Mutation Testing},
	eventtitle = {2018 {IEEE} International Conference on Software Testing, Verification and Validation Workshops ({ICSTW})},
	pages = {47--53},
	booktitle = {2018 {IEEE} International Conference on Software Testing, Verification and Validation Workshops ({ICSTW})},
	publisher = {{IEEE}},
	author = {Petrovic, Goran and Ivankovic, Marko and Kurtz, Bob and Ammann, Paul and Just, Rene},
	urldate = {2024-01-07},
	date = {2018-04},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\M2TFJF2Q\\Petrovic et al. - 2018 - An Industrial Application of Mutation Testing Les.pdf:application/pdf},
}

@article{belli_model-based_2016,
	title = {Model-based mutation testing—Approach and case studies},
	volume = {120},
	issn = {01676423},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167642316000137},
	doi = {10.1016/j.scico.2016.01.003},
	pages = {25--48},
	journaltitle = {Science of Computer Programming},
	shortjournal = {Science of Computer Programming},
	author = {Belli, Fevzi and Budnik, Christof J. and Hollmann, Axel and Tuglular, Tugkan and Wong, W. Eric},
	urldate = {2024-01-07},
	date = {2016-05},
	langid = {english},
	file = {Volltext:C\:\\Users\\lenna\\Zotero\\storage\\Y33LLHM8\\Belli et al. - 2016 - Model-based mutation testing—Approach and case stu.pdf:application/pdf;Volltext:C\:\\Users\\lenna\\Zotero\\storage\\YY26U7GU\\Belli et al. - 2016 - Model-based mutation testing—Approach and case stu.pdf:application/pdf},
}

@book{jorgensen_software_2021,
	location = {Boca Raton, {FL} London New York},
	edition = {Fifth edititon},
	title = {Software testing: a craftsman's approach},
	isbn = {978-0-367-35849-5 978-0-367-76762-4},
	series = {An Auerbach book},
	shorttitle = {Software testing},
	pagetotal = {529},
	publisher = {{CRC} Press, Taylor \& Francis Group},
	author = {Jorgensen, Paul C. and {DeVries}, Byron},
	date = {2021},
	file = {Jorgensen und DeVries - 2021 - Software testing a craftsman's approach.pdf:C\:\\Users\\lenna\\Zotero\\storage\\D3QKGLC3\\Jorgensen und DeVries - 2021 - Software testing a craftsman's approach.pdf:application/pdf},
}

@thesis{heitmuller_user_2023,
	title = {User Partitioning for Anytime Local-Search {MaxSAT} Solvers},
	institution = {{TU} Hamburg},
	type = {Bachelor Thesis},
	author = {Heitmüller, Jan},
	date = {2023-10},
	langid = {english},
	file = {Heitmüller - 2023 - User Partitioning for Anytime Local-Search MaxSAT .pdf:C\:\\Users\\lenna\\Zotero\\storage\\76G8Y2SL\\Heitmüller - 2023 - User Partitioning for Anytime Local-Search MaxSAT .pdf:application/pdf},
}

@online{noauthor_build_2023,
	title = {Build from source on Windows {\textbar} {TensorFlow}},
	url = {https://www.tensorflow.org/install/source_windows},
	urldate = {2024-01-11},
	date = {2023-11-21},
	langid = {english},
	file = {Snapshot:C\:\\Users\\lenna\\Zotero\\storage\\FGTTEVX3\\source_windows.html:text/html},
}
