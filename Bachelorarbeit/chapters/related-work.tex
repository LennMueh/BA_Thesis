In this chapter, we will discuss proposed approaches for repairing neural networks.
These approaches \cite{nakagawa_experience_2023} can be classified into three categories: training-centric, data-centric, and model-centric.

\section{Training-Centric Approaches}\label{sec:training-centric-approaches}
The training centric solution we want to present is AutoTrainer\cite{zhang_autotrainer_2021} an approach to identify varying issues in training vanishing and exploding gradient, dying ReLU oscillating loss and slow convergence.
AutoTrainer first starts training the model and records data on the training like the loss, it then conducts regular analysis to identify possible issues encountered during training.
Upon detecting an issue, the solution scheduler selects an appropriate repair method.
If a problem persists even after trying a solution, the scheduler moves on to the next solution.
This process continues until the issue is resolved, or all solutions are exhausted unsuccessfully.
The solutions that are used are:
\begin{itemize}
    \item Adding Batch Normalization Layers
    \item Substituting Activation Functions
    \item Adding Gradient Clipping
    \item Substituting Initializers
    \item Adjusting Batch Sizes
    \item Adjusting Learning Rates
    \item Substituting Optimizers
\end{itemize}
Another training centric solution is DeepDiagnosis which isn't like AutoTrainer an automatic approach, but more functioning like a debugger.
Hence, it tries to enable the developer to make sound decisions to enhance the training of a DNN.
It monitors the training of the Network and checks for eight error conditions:
\begin{itemize}
    \item Dead Nodes
    \item Saturated Activation Functions
    \item Exploding Tensors
    \item Not increasing Accuracy
    \item Not decreasing Loss
    \item Unchanged Weights
    \item Exploding Gradients
    \item Fading Gradients
\end{itemize}
When these conditions are met, DeepDiagnosis\cite{wardat_deepdiagnosis_2021} makes these findings available to the developer and also provides a recommendation for actionable fixes to the developer.
\section{Data-Centric Approaches}\label{sec:data-centric-approaches}
One data centric approach for the repair of deep neural networks is DeepRepair \cite{yu_deeprepair_2022} which uses a style guided approach to enhance the training data of an DNN. The Idea for this approach is it to mitigate the gap between the training data and the real-world data provided later when the network is in production, which often contains noise patterns.
This is done by the style of guided data augmentation by introducing the noise patterns which are frequently leading to failure.

To make the augmentation more effective, DeepRepair uses a clustering-based method for generating corrupted data, by identifying and grouping similar failure patterns.
There by, it is ensured that the data covers a broader spectrum of potential real-world failure scenarios, enhancing the robustness of the model.

Another data-centric approach is SENSEI \cite{gao_fuzz_2020}, which uses a fuzz testing derived data augmentation approach to bridge the earlier described gap by exposing and mitigating vulnerabilities in DNNs.

\section{Model-Centric Approaches}\label{sec:model-centric-approaches}


\section{DeepFault}\label{sec:deepfault}
DeepFault\cite{eniser_deepfault_2019} is a white-box testing approach for neural networks, developed by Eniser et al. which is according to the Authors.
\begin{quote}
    ... the first fault localization-based white-box testing approach for DNNs.
\end{quote}
There are two objectives to the approach, the identification of suspicious neurons, which have undesirable behaviour, where the respective neuron is suspected to lead to an undesirable outcome in the whole network.
And the synthesis of new inputs for the neural network, to specially retrain the (most) suspicious values.

In this First Part, DeepFault is establishing a Hit Spectrum($HS$) \ref{eq:hit_spectrum} for all neurons, which take the form of a tuple.
The input, and output layers are left out because they are considered inherently correct.
\begin{equation}
    HS_n = (attr_n^{as}, attr_n^{af}, attr_n^{ns}, attr_n^{nf})\label{eq:hit_spectrum}
\end{equation}
\begin{itemize}
    \item $attr^{as}_n$ is the number of times the neuron $n$ is activated in successful test cases.
    \item $attr^{af}_n$ is the number of times the neuron $n$ is activated in failed test cases.
    \item $attr^{ns}_n$ is the number of times the neuron $n$ is not activated in successful test cases.
    \item $attr^{nf}_n$ is the number of times the neuron $n$ is not activated in failed test cases.
\end{itemize}
Then the hit spectra are in a suspiciousness measures, in DeepFault Tarantula \ref{eq: tarantula}, Ochiai \ref{eq: ochiai}, $D^3$ \ref{eq: dstar} are used.
These are not used to identify one wrong neuron, but rather a set of wrong neurons.
For that, the suspiciousness values of the neurons are used to sort the neurons in decreasing order of suspiciousness, if multiple neurons happen to get the same value, the neuron in a deeper layer is used.

Guided by the suspiciousness measures, DeepFault modifies the input, for which the neural network has made the correct decision, in a targeted way.
The synthesis task is supported by a gradient ascent algorithm that aims to determine the degree to which an appropriately classified input should and could be modified to enhance the activation values of suspicious neurons.